{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "05f7c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import contextlib\n",
    "import _pickle as cPickle\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import ast\n",
    "import pickle\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\ae2722\\\\Documents\\\\DCI_code\\\\helperCode')\n",
    "import main_create_model as mm\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b50ef2",
   "metadata": {},
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d407f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ae2722/Documents/DCI_code/'\n",
    "numofhours = 24\n",
    "run = 100\n",
    "client = 'Aachen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d1d4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the data and create train/test split\n",
    "def dataloader_used(path, client, numofhours):\n",
    "    dfs = ['X_train_norm', 'X_test_norm', 'X_val_norm', 'y_train', 'y_test', 'y_val']\n",
    "    for i, df in zip(range(6), dfs):\n",
    "        globals()[df] = pd.read_excel(open(f'{path}client/Data_subpopn/dataset_client_{client}_{numofhours}.xlsx', 'rb'),\n",
    "                  sheet_name=f'sheet{i}', index_col = 0)\n",
    "    return X_train_norm, X_test_norm, X_val_norm, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c409931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_full(client, path, numofhours):\n",
    "    ##load the data and create train/test split\n",
    "    keys = ['HR', 'AR-M', 'AR-D', 'AR-S', 'SPO2', 'RR']\n",
    "    target = 'label'\n",
    "    IDcol = 'Shopid'\n",
    "    hourscol = 'hours'\n",
    "    start_time = 24*3\n",
    "    k_feat = 70\n",
    "\n",
    "    all_predictors, labelsvals, demfeats_vals = mm.load_data_all(univ_type=client,include_dems = True)\n",
    "        \n",
    "    predictor_keys = mm.get_predictor(keys)\n",
    "    demo_predictor_keys = mm.get_dem_predictors() \n",
    "\n",
    "    continuous_cols = np.array(predictor_keys)\n",
    "    continuous_cols = np.append(continuous_cols, np.array(demo_predictor_keys)[[0, 5]])\n",
    "    categorical_cols = np.array(demo_predictor_keys)[[1,2,3,4]]\n",
    "\n",
    "    X, y = mm.create_data_input(all_predictors, start_time, IDcol, predictor_keys, demfeats_vals, labelsvals, numofhours)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8927782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD LR\n",
    "def load_LR_weights(path, client, numofhours, run):\n",
    "    model = tf.keras.models.load_model(f'{path}server/model_full/server_models/best_model/LR/client_{client}_{numofhours}_{run}.h5')\n",
    "    weights = model.layers[0].get_weights()[0].reshape(1,-1)[0]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63aa3b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load SVM\n",
    "def load_SVM_model(path, client, numofhours, run):\n",
    "    with open(f'{path}client/model/SVM/SVM_{client}_{numofhours}_{run}.pkl', 'rb') as f:\n",
    "        return  cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0b9e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the rf  model\n",
    "def load_RF_feature_imp(path, client, numofhours, run):\n",
    "    with open(f'{path}server/model_full/server_models/best_model/RF/RF_{client}_{numofhours}_{run}.pkl', 'rb') as f:\n",
    "        model =  cPickle.load(f)\n",
    "    return model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "439931e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(features, model):\n",
    "    for m in model:\n",
    "        if m in features:\n",
    "            features[m] +=1\n",
    "        else:\n",
    "            features[m] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b435e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imp_features(path, client):\n",
    "    numofhours_all = [i for i in range(24,157,12)]\n",
    "    features_all = {}\n",
    "    X,y = dataloader_full(client, path, 24)\n",
    "    for numofhours in numofhours_all:\n",
    "        features = {}\n",
    "        for i in range(300):\n",
    "            try:\n",
    "                lr = load_LR_weights(path, client, numofhours, i)\n",
    "                rf = load_RF_feature_imp(path, client, numofhours, i)\n",
    "                lr_3 = np.argsort(abs(lr))[-5:][::-1]\n",
    "                rf_3 = np.argsort(abs(rf))[-5:][::-1]\n",
    "                features = add_to_dict(features, lr_3)\n",
    "                features = add_to_dict(features, rf_3)\n",
    "            except:\n",
    "                pass\n",
    "        counts = pd.DataFrame.from_dict(features, orient = 'index', columns = ['count']).sort_values(by = 'count',ascending = False)\n",
    "        columns_imp = counts.iloc[:5].index\n",
    "        X_train_norm, X_test_norm, X_val_norm, y_train, y_test, y_val = dataloader_used(path, client, numofhours)\n",
    "        column_index = X_train_norm.iloc[:,columns_imp].columns\n",
    "        features = list(X.iloc[:, column_index].columns)\n",
    "        features_all[numofhours] = features\n",
    "    return features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b9e39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = get_imp_features(path, 'Aachen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "32167356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(Mean_SPO2, nanmean)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_RR, maxminRange_)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_SPO2, entropy_)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_RR, maxminRange_)</td>\n",
       "      <td>(Mean_SPO2, entropy_)</td>\n",
       "      <td>(Mean_SPO2, nanmean)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(Mean_SPO2, nanmean)</td>\n",
       "      <td>(STD_SPO2, maxminRange_)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_AR-M, entropy_)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(STD_SPO2, entropy_)</td>\n",
       "      <td>(Mean_SPO2, nanmean)</td>\n",
       "      <td>(STD_HR, nanmean)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(STD_HR, nanmean)</td>\n",
       "      <td>(STD_SPO2, entropy_)</td>\n",
       "      <td>(Mean_SPO2, nanmean)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(Mean_SPO2, nanmean)</td>\n",
       "      <td>(STD_HR, maxminRange_)</td>\n",
       "      <td>(STD_SPO2, entropy_)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(STD_HR, nanmean)</td>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_RR, entropy_)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_SPO2, nanstd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_RR, entropy_)</td>\n",
       "      <td>(STD_HR, nanmean)</td>\n",
       "      <td>(Mean_SPO2, nanmean)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_RR, entropy_)</td>\n",
       "      <td>(Mean_HR, entropy_)</td>\n",
       "      <td>(STD_HR, nanmean)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_AR-D, nanmedian)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_RR, entropy_)</td>\n",
       "      <td>(STD_HR, IQR_Range)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_AR-D, nanmedian)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_AR-D, nanmean)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>(Mean_HR, nanmean)</td>\n",
       "      <td>(STD_HR, IQR_Range)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_AR-S, nanmedian)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_AR-S, nanmean)</td>\n",
       "      <td>(Mean_max_Xcorr_HR_SPO2, entropy_)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>(STD_HR, nanstd)</td>\n",
       "      <td>(STD_HR, maxminRange_)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_AR-S, nanmean)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_AR-S, nanmedian)</td>\n",
       "      <td>(Mean_min_Xcorr_HR_SPO2, entropy_)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0                                   1  \\\n",
       "24                  (Mean_HR, entropy_)  (Mean_min_Xcorr_HR_SPO2, entropy_)   \n",
       "36                  (Mean_HR, entropy_)  (Mean_min_Xcorr_HR_SPO2, entropy_)   \n",
       "48                  (Mean_HR, entropy_)  (Mean_min_Xcorr_HR_SPO2, entropy_)   \n",
       "60                  (Mean_HR, entropy_)  (Mean_min_Xcorr_HR_SPO2, entropy_)   \n",
       "72                  (Mean_HR, entropy_)  (Mean_min_Xcorr_HR_SPO2, entropy_)   \n",
       "84                  (Mean_HR, entropy_)  (Mean_min_Xcorr_HR_SPO2, entropy_)   \n",
       "96   (Mean_min_Xcorr_HR_SPO2, entropy_)                   (STD_HR, nanmean)   \n",
       "108  (Mean_min_Xcorr_HR_SPO2, entropy_)                 (Mean_HR, entropy_)   \n",
       "120  (Mean_min_Xcorr_HR_SPO2, entropy_)    (Mean_max_Xcorr_HR_RR, entropy_)   \n",
       "132  (Mean_min_Xcorr_HR_SPO2, entropy_)    (Mean_max_Xcorr_HR_RR, entropy_)   \n",
       "144                  (Mean_HR, nanmean)                 (STD_HR, IQR_Range)   \n",
       "156                    (STD_HR, nanstd)              (STD_HR, maxminRange_)   \n",
       "\n",
       "                                        2  \\\n",
       "24                   (Mean_SPO2, nanmean)   \n",
       "36   (Mean_min_Xcorr_HR_RR, maxminRange_)   \n",
       "48                   (Mean_SPO2, nanmean)   \n",
       "60                   (STD_SPO2, entropy_)   \n",
       "72                      (STD_HR, nanmean)   \n",
       "84                   (Mean_SPO2, nanmean)   \n",
       "96                    (Mean_HR, entropy_)   \n",
       "108      (Mean_max_Xcorr_HR_RR, entropy_)   \n",
       "120                   (Mean_HR, entropy_)   \n",
       "132                   (STD_HR, IQR_Range)   \n",
       "144   (Mean_min_Xcorr_HR_AR-S, nanmedian)   \n",
       "156     (Mean_min_Xcorr_HR_AR-S, nanmean)   \n",
       "\n",
       "                                        3                                    4  \n",
       "24   (Mean_min_Xcorr_HR_RR, maxminRange_)   (Mean_max_Xcorr_HR_SPO2, entropy_)  \n",
       "36                  (Mean_SPO2, entropy_)                 (Mean_SPO2, nanmean)  \n",
       "48               (STD_SPO2, maxminRange_)   (Mean_max_Xcorr_HR_AR-M, entropy_)  \n",
       "60                   (Mean_SPO2, nanmean)                    (STD_HR, nanmean)  \n",
       "72                   (STD_SPO2, entropy_)                 (Mean_SPO2, nanmean)  \n",
       "84                 (STD_HR, maxminRange_)                 (STD_SPO2, entropy_)  \n",
       "96       (Mean_max_Xcorr_HR_RR, entropy_)     (Mean_max_Xcorr_HR_SPO2, nanstd)  \n",
       "108                     (STD_HR, nanmean)                 (Mean_SPO2, nanmean)  \n",
       "120                     (STD_HR, nanmean)  (Mean_max_Xcorr_HR_AR-D, nanmedian)  \n",
       "132   (Mean_max_Xcorr_HR_AR-D, nanmedian)    (Mean_max_Xcorr_HR_AR-D, nanmean)  \n",
       "144     (Mean_min_Xcorr_HR_AR-S, nanmean)   (Mean_max_Xcorr_HR_SPO2, entropy_)  \n",
       "156   (Mean_min_Xcorr_HR_AR-S, nanmedian)   (Mean_min_Xcorr_HR_SPO2, entropy_)  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aachen = pd.DataFrame.from_dict(features_all, orient = 'index')\n",
    "df_aachen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ecdb4d",
   "metadata": {},
   "source": [
    "## Feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cdfd39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_plot = {}\n",
    "outcomes = {}\n",
    "numofhours_all = [i for i in range(24,157,12)]\n",
    "clients = ['CUMC', 'UTH', 'Aachen']\n",
    "feat = pd.unique(df_aachen.values.ravel('K'))\n",
    "for client in clients:\n",
    "    features_plot[client] = {}\n",
    "    for numofhours in numofhours_all:\n",
    "        X, y = dataloader_full(client, path, numofhours)\n",
    "        features_plot[client][numofhours] = X.loc[:,feat]\n",
    "        outcomes[client] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "24ff5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dfs = {}\n",
    "feats = pd.unique(df_aachen.values.ravel('K'))\n",
    "for f in feats:\n",
    "    plot_dfs[f] = {}\n",
    "    for client in clients:\n",
    "        df = pd.DataFrame()\n",
    "        for numofhours in numofhours_all:\n",
    "            feat_ = features_plot[client][numofhours].loc[:,f]\n",
    "            feat_ = pd.DataFrame(feat_)\n",
    "            feat_.columns = [f\"{numofhours}_{pair[0]}_{pair[1]}\" for pair in feat_.columns]\n",
    "            df = pd.concat([df,feat_], axis = 1)\n",
    "        df_T = df.T\n",
    "        df_T.index = numofhours_all\n",
    "        plot_dfs[f][client] =  df_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "5144e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path}server/results/feature_distributions.pkl\", 'wb') as handle:\n",
    "    #pickle.dump(plot_dfs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f\"{path}server/results/outcomes.pkl\", 'wb') as handle:\n",
    "    pickle.dump(outcomes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d21e59b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path}server/results/feature_distributions.pkl\", 'rb') as handle:\n",
    "    a = pickle.load(handle)\n",
    "    \n",
    "with open(f\"{path}server/results/outcomes.pkl\", 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "03c668ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grapher_box(f, plot_dfs, group, hours):\n",
    "    figure(figsize = (15, 10), dpi = 80)\n",
    "    graph = pd.DataFrame()\n",
    "    for client in clients:\n",
    "        groups = {1.0:'DCI+', 0.0:'DCI-', 'all':'all'}\n",
    "        \n",
    "        df = plot_dfs[f][client]\n",
    "        df = df.loc[hours]\n",
    "        if group != 'all':\n",
    "            df_ = df.loc[:,outcomes[client].index[outcomes[client]['label'] == group]]\n",
    "        else:\n",
    "            df_ = df \n",
    "        boxplot_stats(df)\n",
    "        data = df_.reset_index().melt(id_vars = 'index')\n",
    "        data.drop('Shopid', axis = 1, inplace = True)\n",
    "        data['site'] = client\n",
    "        outliers = boxplot_stats(data['value'])[0]['fliers']\n",
    "        data = data[~data['value'].isin(outliers)]\n",
    "        graph = pd.concat([graph, data])\n",
    "    \n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (12,10))\n",
    "    sns.boxplot(x = graph['index'], y = graph['value'], hue = graph['site'], fliersize = 0, ax = ax)\n",
    "    x = f[0].strip('(').strip(')')\n",
    "    x = x + f'_{f[1]}'\n",
    "    \n",
    "    plt.title(f'Distribution_for_{x}_{groups[group]}')\n",
    "    plt.xlabel('Hours from DCI')\n",
    "    plt.xticks(ticks = hours, labels = hours)\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(bbox_to_anchor = (1,1))\n",
    "    plt.plot()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "d56e1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grapher_line(f, plot_dfs, group, hours):\n",
    "    figure(figsize = (15, 10), dpi = 80)\n",
    "    graph = pd.DataFrame()\n",
    "    for client in clients:\n",
    "        groups = {1.0:'DCI+', 0.0:'DCI-', 'all':'all'}\n",
    "        \n",
    "        df = plot_dfs[f][client]\n",
    "        df = df.loc[hours]\n",
    "        if group != 'all':\n",
    "            df_ = df.loc[:,outcomes[client].index[outcomes[client]['label'] == group]]\n",
    "        else:\n",
    "            df_ = df \n",
    "        \n",
    "        data = (pd.DataFrame(df_.mean(axis = 1), columns = [client]))\n",
    "        graph = pd.concat([graph, data])\n",
    "    \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        sns.set_theme('white')\n",
    "        y_errormin = df_.apply(lambda x: np.percentile(x, 50), axis = 1)  - df_.apply(lambda x: np.percentile(x, 49), axis = 1) \n",
    "        y_errormax = df_.apply(lambda x: np.percentile(x, 80), axis = 1) - df_.apply(lambda x: np.percentile(x, 50), axis = 1) \n",
    "        y_error = np.array([y_errormin, y_errormax])\n",
    "        plt.errorbar(df_.index,df_.apply(lambda x: np.percentile(x, 50), axis = 1),\n",
    "                     yerr = y_error,\n",
    "                    label = client,\n",
    "                    alpha = 0.7,\n",
    "                    linestyle = '-')\n",
    "        '''\n",
    "    fig, ax = plt.subplots(figsize = (12,10))\n",
    "    sns.lineplot(data = graph, ax = ax)\n",
    "    x = f[0].strip('(').strip(')')\n",
    "    x = x + f'_{f[1]}'\n",
    "    \n",
    "    plt.title(f'Distribution_for_{x}_{groups[group]}')\n",
    "    plt.xlabel('Hours from DCI')\n",
    "    plt.xticks(ticks = hours, labels = hours)\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(bbox_to_anchor = (1,1))\n",
    "    plt.plot()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "c69df4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grapher_kde(f, plot_dfs, group, hour):\n",
    "    graph = pd.DataFrame()\n",
    "    groups = {1.0:'DCI+', 0.0:'DCI-', 'all':'all'}\n",
    "    \n",
    "    for client in clients:\n",
    "        df = plot_dfs[f][client]\n",
    "        df = df.loc[[hour]]\n",
    "        if group != 'all':\n",
    "            df_ = df.loc[:,outcomes[client].index[outcomes[client]['label'] == group]]\n",
    "        else:\n",
    "            df_ = df \n",
    "        \n",
    "        df_T = df_.T\n",
    "        df_T.columns = [client]\n",
    "        df_T.reset_index(inplace = True)\n",
    "        df_T.drop('Shopid', axis = 1, inplace = True)\n",
    "        \n",
    "        sns.kdeplot(x = df_T[client], label = client, common_norm = False)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        graph = pd.concat([graph, df_T], axis = 1)\n",
    "        df_['site'] = client\n",
    "        df_ = df_.reset_index().melt(id_vars = 'site').drop('Shopid', axis = 1).iloc[1:]\n",
    "        graph = pd.concat([graph, df_])\n",
    "    \n",
    "    graph = graph[graph['value'].isna() == False]\n",
    "    graph = graph.reset_index(drop = True)\n",
    "    sns.kdeplot(x = graph['value'], hue = graph['site'], hue_order = clients, common_norm = False)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    x = f[0].strip('(').strip(')')\n",
    "    x = x + f'_{f[1]}'\n",
    "    plt.legend(labels = clients)\n",
    "    plt.title(f'Distribution_for_{x}_{groups[group]}_hours: {hour}')\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
