{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1eebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import argparse\n",
    "import concurrent.futures\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import spur\n",
    "import subprocess\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn import metrics\n",
    "sns.set()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e7a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the keras model (LR in this case)\n",
    "def create_LR_model():\n",
    "    initializer = tf.keras.initializers.Constant(value=0)\n",
    "    ##build LR model\n",
    "    number_of_classes = 1\n",
    "    number_of_features = 70\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes,activation = 'sigmoid',\n",
    "                                    input_dim = number_of_features,\n",
    "                                   kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2855c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_clients(path, numofhours):\n",
    "    ##clear models from clients\n",
    "    command = f'del /S C:{path}client/model/LR/*_{numofhours}*  {path}server/model/server_models/best_model/LR/*_{numofhours}* {path}server/model/server_models/current_model/LR/*_{numofhours}*' \n",
    "    command = command.replace('/',\"\\\\\")\n",
    "    command = f'{command} /s /q'\n",
    "    subprocess.call(command, shell = True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f474c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clients(client, path, epochs, test, numofhours, run):\n",
    "    ##send model to clients\n",
    "    if test:\n",
    "        command = f'xcopy \"{path}server/model/server_models/best_model/LR/client_{client}_{numofhours}_{run}.h5\" \"C:{path}client/model/LR/\"'\n",
    "    else:\n",
    "        command = f'xcopy \"{path}server/model/server_models/current_model/LR/client_{client}_{numofhours}_{run}.h5\" \"C:{path}client/model/LR/\"'\n",
    "    ##parse the copy command\n",
    "    command = command.replace('/',\"\\\\\")\n",
    "    command = f'{command} /e /s /y'\n",
    "    subprocess.call(command, shell = True) \n",
    "    \n",
    "    ##Run script\n",
    "    command = f'python {path}client/clientServer-LR.py -cl={client} -ep={epochs} -ts={test} -hr={numofhours} -rn={run} -en=False'\n",
    "    command = command.split(' ')\n",
    "    output = subprocess.check_output(command) \n",
    "    server_response = output.decode('utf-8').split(' ')\n",
    "    return server_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b12a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedAvg(models, relative_weights):\n",
    "    params = [models[m].get_weights() for m in models ]\n",
    "    new_weights = []\n",
    "    for weights_list_tuple in zip(*params):\n",
    "        new_weights.append(np.array([np.average(np.array(\n",
    "            weights_), axis=0, weights=relative_weights) for weights_ in zip(*weights_list_tuple)]))\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5051dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateResults(response):\n",
    "    # Check if the current validation is better than the previous best one\n",
    "    sizes = np.array([x[0] for x in response.values()]) \n",
    "    weights = sizes / np.sum(sizes)\n",
    "\n",
    "    scores = np.array([x[4] for x in response.values()]) \n",
    "    current_auc = np.sum(scores*weights)\n",
    "    \n",
    "    return current_auc, scores, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548f6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processResponse(command):\n",
    "        # Retrieve server responses and parse\n",
    "        result = [x.replace('\\r\\n','').replace('copiedX_train_normX_test_normX_val_normy_trainy_testy_val','') for x in command.result()[2:]]\n",
    "        server_1_response = [float(j) for j in result]\n",
    "        return server_1_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde1fff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5872/1157252538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5872/1157252538.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-s0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'--centralServer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-s1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'--clientServer_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-s2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'--clientServer_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-s0','--centralServer', default = '')\n",
    "    parser.add_argument('-cl','--clients', default = '')\n",
    "    parser.add_argument('-pt','--path', default = '/Users/ae2722/Documents/DCI_code/')\n",
    "    parser.add_argument('-hr','--hours')\n",
    "    parser.add_argument('-rn','--run')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    centralServer = args.centralServer\n",
    "    clients = args.clients\n",
    "    path = args.path\n",
    "    numofhours = args.hours\n",
    "    run = args.run\n",
    "    clients = clients.split(',')\n",
    "\n",
    "\n",
    "\n",
    "     # Hyperparameters\n",
    "    patience = 5\n",
    "    epochs = 20\n",
    "\n",
    "    # Delete past client data\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        executor.submit(clear_clients, path)\n",
    "\n",
    "    # Model architecture\n",
    "    #LR\n",
    "    for client in clients:\n",
    "        federated_model_LR = create_LR_model()\n",
    "        federated_model_LR.save(f'{path}server/model/server_models/current_model/LR/client_{client}_{numofhours}_{run}.h5', save_format = 'h5')\n",
    "        federated_model_LR.save(f'{path}server/model/server_models/best_model/LR/client_{client}_{numofhours}_{run}.h5', save_format = 'h5')\n",
    "\n",
    "    # Set runtime parameters\n",
    "    patience_counter = 0\n",
    "    iterations = 0\n",
    "    highest_auc = 0\n",
    "    early_stopping = False\n",
    "    test = False\n",
    "    while (early_stopping == False) and (iterations < 20):\n",
    "        # Run model\n",
    "        commands = {}\n",
    "        response = {}\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for client in clients:\n",
    "                commands[client] = executor.submit(run_clients, client, path, epochs, test, numofhours, run)\n",
    "        for client in clients:\n",
    "            # Retrieve server responses\n",
    "            response[client] = processResponse(commands[client])\n",
    "\n",
    "        # Wait until the two servers return their weights files\n",
    "        while sum([f'_{numofhours}_{run}' in x for x in  list(set(os.listdir(f'{path}server/model/client_models/LR')))]) != len(clients):\n",
    "            time.sleep(5)\n",
    "        current_auc, client_auc, weights = validateResults(response)\n",
    "        print(current_auc, client_auc)\n",
    "\n",
    "        # Load models\n",
    "        models = {}\n",
    "        for client in clients:\n",
    "            models[client] = tf.keras.models.load_model(f'{path}server/model/client_models/LR/client_{client}_{numofhours}_{run}.h5')\n",
    "\n",
    "        #Replace best models if applicable\n",
    "        if current_auc > highest_auc:\n",
    "            patience_counter = 0\n",
    "            for client in clients:\n",
    "                models[client].save(f'{path}server/model/server_models/best_model/LR/client_{client}_{numofhours}_{run}.h5', save_format = 'h5')\n",
    "                highest_auc = current_auc\n",
    "            print(f'Validation AUC: {current_auc}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Conduct federated averaging to update the federated_model if we have not exceeded patience\n",
    "        if patience_counter > patience:\n",
    "            early_stopping = True\n",
    "            test = True\n",
    "        else:\n",
    "\n",
    "            new_weights = fedAvg(models, weights)\n",
    "            for client in clients:\n",
    "                models[client].set_weights(new_weights)\n",
    "                models[client].save(f'{path}server/model/server_models/current_model/LR/client_{client}_{numofhours}_{run}.h5', save_format = 'h5')\n",
    "        iterations +=1\n",
    "\n",
    "        if iterations >= 20:\n",
    "            test = True\n",
    "\n",
    "\n",
    "    if test:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for client in clients:\n",
    "                commands[client] = executor.submit(run_clients, client, path, epochs, test, numofhours, run)\n",
    "        for client in clients:\n",
    "            # Retrieve server responses\n",
    "            response[client] = [float(x.replace('\\r\\n','').replace('X_train_normX_test_normX_val_normy_trainy_testy_val','')) for x in commands[client].result()]\n",
    "\n",
    "        current_auc, client_auc, weights = validateResults(response)\n",
    "\n",
    "        print(f'Test AUC: {current_auc}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
