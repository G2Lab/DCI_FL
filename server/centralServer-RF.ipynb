{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1eebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import argparse\n",
    "import concurrent.futures\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import spur\n",
    "import subprocess\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import _pickle as cPickle\n",
    "sns.set()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e7a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create the keras model RF in this case)\n",
    "def create_RF_model(path, client, numofhours, run):\n",
    "    model = RandomForestClassifier(max_depth=5, max_features = 'log2', criterion = 'gini', random_state=0)\n",
    "    with open(f'{path}server/model/server_models/current_model/RF/RF_{client}_{numofhours}_{run}.pkl', 'wb') as f:\n",
    "        cPickle.dump(model, f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286549b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the rf  model\n",
    "def save_RF_model(location, client_model):\n",
    "    with open(f'{location}.pkl', 'wb') as f:\n",
    "        cPickle.dump(client_model, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208bbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the rf  model\n",
    "def load_RF_model(location):\n",
    "    with open(f'{location}.pkl', 'rb') as f:\n",
    "        return  cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2855c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_clients(client, path, numofhours):\n",
    "    ##clear models from clients\n",
    "    command = f'del C:{path}client/model/RF/RF_{client}_{numofhours}*.pkl'\n",
    "    command = command.replace('/',\"\\\\\")\n",
    "    command = f'{command} /s /q'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f474c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clients(client, path, test, numofhours, run):\n",
    "    ##send model to clients\n",
    "    command = f'xcopy \"C:{path}server/model/server_models/current_model/RF/RF_{client}_{numofhours}_{run}.pkl\" \"C:{path}client/model/RF/\"'\n",
    "    ##parse the copy command\n",
    "    command = command.replace('/',\"\\\\\")\n",
    "    command = f'{command} /e /s /y'\n",
    "    subprocess.call(command, shell = True) \n",
    "    \n",
    "    ##Run script\n",
    "    command = f'python {path}client/clientServer-RF.py -cl={client} -ts={test} -en=False -hr={numofhours} -rn={run}'\n",
    "    command = command.split(' ')\n",
    "    output = subprocess.check_output(command) \n",
    "    server_response = output.decode('utf-8').split(' ')\n",
    "    return server_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b12a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedAvg(models, relative_weights):\n",
    "    ##extract individual trees\n",
    "    client_trees = [models[model].estimators_ for model in models]\n",
    "    ##assign number of trees\n",
    "    num_trees = [round(len(client_trees[0])*weight) for weight in relative_weights]\n",
    "    ##sample from both forests\n",
    "    new_forest = []\n",
    "    np.random.seed(2)\n",
    "    for i in range(len(client_trees)):\n",
    "        new_forest.extend(list(np.random.choice(client_trees[i], num_trees[i])))\n",
    "    ##assign to models\n",
    "    for model in models:\n",
    "        models[model].estimators_ = new_forest\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5051dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateResults(response):\n",
    "    # Check if the current validation is better than the previous best one\n",
    "    sizes = np.array([x[0] for x in response.values()]) \n",
    "    weights = sizes / np.sum(sizes)\n",
    "\n",
    "    scores = np.array([x[2] for x in response.values()]) \n",
    "    current_auc = np.sum(scores*weights)\n",
    "    \n",
    "    return current_auc, scores, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f5f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processResponse(command):\n",
    "        # Retrieve server responses and parse\n",
    "        result = [x.replace('\\r\\n','').replace('copied','') for x in command.result()[2:]]\n",
    "        server_1_response = [float(j) for j in result]\n",
    "        return server_1_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-s0','--centralServer', default = '')\n",
    "    parser.add_argument('-cl','--clients', default = '')\n",
    "    parser.add_argument('-pt','--path', default = '/Users/ae2722/Documents/DCI_code/')\n",
    "    parser.add_argument('-hr','--hours')\n",
    "    parser.add_argument('-rn','--run')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    centralServer = args.centralServer\n",
    "    clients = args.clients\n",
    "    path = args.path\n",
    "    numofhours = args.hours\n",
    "    run = args.run\n",
    "    \n",
    "    clients = clients.split(',')\n",
    "    \n",
    "    # Delete past client data\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        executor.submit(clear_clients, path, numofhours)\n",
    "\n",
    "    # Model architecture\n",
    "    for client in clients:\n",
    "        model = create_RF_model(path, client, numofhours, run)\n",
    "    # Set runtime parameters\n",
    "    test = False\n",
    "\n",
    "    # Run model\n",
    "    commands = {}\n",
    "    response = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        for client in clients:\n",
    "            commands[client] = executor.submit(run_clients, client, path, test, numofhours, run)\n",
    "    for client in clients:\n",
    "        # Retrieve server responses\n",
    "        response[client] = processResponse(commands[client])\n",
    "\n",
    "    # Wait until the two servers return their weights files\n",
    "    while sum([f'_{numofhours}_{run}' in x for x in  list(set(os.listdir(f'{path}server/model/client_models/RF')))]) != len(clients):\n",
    "        time.sleep(5)\n",
    "    current_auc, client_auc, weights = validateResults(response)\n",
    "    print(current_auc, client_auc)\n",
    "\n",
    "\n",
    "    # Load models\n",
    "    models = {}\n",
    "    for client in clients:\n",
    "        models[client] = load_RF_model(f'{path}server/model/client_models/RF/RF_{client}_{numofhours}_{run}')\n",
    "\n",
    "\n",
    "    # Conduct federated averaging to update the federated_model\n",
    "    models = fedAvg(models, weights)\n",
    "    for client in clients:\n",
    "        save_RF_model(f'{path}server/model/server_models/current_model/RF/RF_{client}_{numofhours}_{run}', models[client])\n",
    "\n",
    "\n",
    "    test = True\n",
    "\n",
    "    if test:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for client in clients:\n",
    "                commands[client] = executor.submit(run_clients, client, path, test, numofhours, run)\n",
    "        for client in clients:\n",
    "            # Retrieve server responses\n",
    "            response[client] = [float(x.replace('\\r\\n','')) for x in commands[client].result()]\n",
    "\n",
    "        current_auc, client_auc, weights = validateResults(response)\n",
    "\n",
    "        print(f'Test AUC: {current_auc}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
